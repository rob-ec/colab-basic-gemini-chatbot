{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rob-ec/colab-basic-gemini-chatbot/blob/main/basic_gemini_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMP-Brd0PiI-"
      },
      "source": [
        "# Chatbot com Gemini AI\n",
        "\n",
        "`@author` Robson Gomes <dev@robsongomes.me>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8X_8YaSP3sC"
      },
      "source": [
        "## Instalação de dependências e Importaçãoes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzvV_5oeWdwf"
      },
      "source": [
        "### Instalações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWU6UaznPgb4"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx5gq4pxQGnd"
      },
      "source": [
        "### Importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sINVIyDeQFSU"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXTBCyc_Q89E"
      },
      "source": [
        "## Configurações"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2qSbnSQWsfM"
      },
      "source": [
        "### Chave API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "G9KiTMf1Qerp"
      },
      "outputs": [],
      "source": [
        "# @title Definindo Chave API {display-mode: \"form\"}\n",
        "API_KEY = \"COLE_AQUI_SUA_CHAVE_DA_API\" #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementando chave"
      ],
      "metadata": {
        "id": "rj8HR6FxDs6f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO_NJCCKRK9A"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key = API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDxnEVFYo3jL"
      },
      "source": [
        "### Funções auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Me90B_OckA7"
      },
      "outputs": [],
      "source": [
        "def displayObjectsAsTable(objects):\n",
        "  keys = objects[0].__dict__.keys()\n",
        "  rows = []\n",
        "\n",
        "  for obj in objects:\n",
        "    row = f\"| {'|'.join(str(getattr(obj, key)) for key in keys)} |\"\n",
        "    rows.append(row)\n",
        "\n",
        "  header = ' | '.join(keys)\n",
        "  tableRows = \"\\n\".join(rows)\n",
        "  table = f\"|{header}|\\n|{'--|'*len(keys)}\\n{tableRows}\"\n",
        "\n",
        "  display(Markdown(table))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def displayAsJSON(dict):\n",
        "  display(Markdown(\"```JSON\\n\" + json.dumps(dict, indent=4) + \"\\n```\"))"
      ],
      "metadata": {
        "id": "BnoPCctWXeSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyAarjqypTX8"
      },
      "outputs": [],
      "source": [
        "def getModelsNames(models):\n",
        "  return [model.name[7:] for model in models]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def displayModels(models, headers = [\"Título\", \"Nome\"]):\n",
        "  header = ' | '.join(headers)\n",
        "\n",
        "  rows = []\n",
        "\n",
        "  for model in models:\n",
        "    rows.append(f\"| {model.display_name} | `{model.name[7:]}` |\")\n",
        "\n",
        "  tableRows = \"\\n\".join(rows)\n",
        "  table = f\"|{header}|\\n|{'--|'*len(headers)}\\n{tableRows}\"\n",
        "\n",
        "  display(Markdown(table))\n"
      ],
      "metadata": {
        "id": "_Ps3ENmdG276"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qfP1NSbWJ5l"
      },
      "source": [
        "### Modelos disponíveis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoqBLXQ9o_Y7"
      },
      "source": [
        "#### Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "D0dBkLFDReGs",
        "outputId": "b7f4eab7-62f8-43d6-d2c8-ebb19cba7ee2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "|name | base_model_id | version | display_name | description | input_token_limit | output_token_limit | supported_generation_methods | temperature | top_p | top_k|\n|--|--|--|--|--|--|--|--|--|--|--|\n| models/gemini-1.0-pro||001|Gemini 1.0 Pro|The best model for scaling across a wide range of tasks|30720|2048|['generateContent', 'countTokens']|0.9|1.0|None |\n| models/gemini-1.0-pro-001||001|Gemini 1.0 Pro 001 (Tuning)|The best model for scaling across a wide range of tasks. This is a stable model that supports tuning.|30720|2048|['generateContent', 'countTokens', 'createTunedModel']|0.9|1.0|None |\n| models/gemini-1.0-pro-latest||001|Gemini 1.0 Pro Latest|The best model for scaling across a wide range of tasks. This is the latest model.|30720|2048|['generateContent', 'countTokens']|0.9|1.0|None |\n| models/gemini-1.0-pro-vision-latest||001|Gemini 1.0 Pro Vision|The best image understanding model to handle a broad range of applications|12288|4096|['generateContent', 'countTokens']|0.4|1.0|32 |\n| models/gemini-1.5-pro-latest||001|Gemini 1.5 Pro|Mid-size multimodal model that supports up to 1 million tokens|1048576|8192|['generateContent', 'countTokens']|1.0|0.95|None |\n| models/gemini-pro||001|Gemini 1.0 Pro|The best model for scaling across a wide range of tasks|30720|2048|['generateContent', 'countTokens']|0.9|1.0|None |\n| models/gemini-pro-vision||001|Gemini 1.0 Pro Vision|The best image understanding model to handle a broad range of applications|12288|4096|['generateContent', 'countTokens']|0.4|1.0|32 |"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title { display-mode: \"form\" }\n",
        "modelList = []\n",
        "\n",
        "for model in genai.list_models():\n",
        "  if 'generateContent' in model.supported_generation_methods:\n",
        "    modelList.append(model)\n",
        "\n",
        "displayObjectsAsTable(modelList)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tguYDTcVrWG6"
      },
      "source": [
        "### Parâmetros de Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-cvgT90W0s8"
      },
      "outputs": [],
      "source": [
        "# @title Configuração de IA Generativa { display-mode: \"form\", run: \"auto\" }\n",
        "# @markdown `generation_config`:\n",
        "\n",
        "candidate_count = 1 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "temperature = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "top_k = 32 #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "generation_config = {\n",
        "    \"candidate_count\": candidate_count,\n",
        "    \"temperature\": temperature,\n",
        "    \"top_k\": top_k,\n",
        "    \"top_p\": top_p,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CO3PUfBri54"
      },
      "outputs": [],
      "source": [
        "# @title Segurança { display-mode: \"form\", run: \"auto\" }\n",
        "# @markdown `safety_config`:\n",
        "\n",
        "harassment_content_policy = \"BLOCK_MEDIUM_AND_ABOVE\" # @param [\"BLOCK_NONE\", \"BLOCK_ONLY_HIGH\", \"BLOCK_MEDIUM_AND_ABOVE\", \"BLOCK_LOW_AND_ABOVE\"]\n",
        "hate_speech_content_policy = \"BLOCK_MEDIUM_AND_ABOVE\" # @param [\"BLOCK_NONE\", \"BLOCK_ONLY_HIGH\", \"BLOCK_MEDIUM_AND_ABOVE\", \"BLOCK_LOW_AND_ABOVE\"]\n",
        "sexually_explicit_content_policy = \"BLOCK_MEDIUM_AND_ABOVE\" # @param [\"BLOCK_NONE\", \"BLOCK_ONLY_HIGH\", \"BLOCK_MEDIUM_AND_ABOVE\", \"BLOCK_LOW_AND_ABOVE\"]\n",
        "dangerous_content_policy = \"BLOCK_MEDIUM_AND_ABOVE\" # @param [\"BLOCK_NONE\", \"BLOCK_ONLY_HIGH\", \"BLOCK_MEDIUM_AND_ABOVE\", \"BLOCK_LOW_AND_ABOVE\"]\n",
        "\n",
        "safety_config = {\n",
        "    \"HARASSMENT\": harassment_content_policy,\n",
        "    \"HATE\": hate_speech_content_policy,\n",
        "    \"SEXUAL\": sexually_explicit_content_policy,\n",
        "    \"DANGEROUS\": dangerous_content_policy,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecionar Modelo"
      ],
      "metadata": {
        "id": "34Mmk_ILBRH5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTHwKjAf3Y_r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "2ad5e442-3a39-4f1f-a385-d529cd2997f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "|Título | Nome|\n|--|--|\n| Gemini 1.0 Pro | `gemini-1.0-pro` |\n| Gemini 1.0 Pro 001 (Tuning) | `gemini-1.0-pro-001` |\n| Gemini 1.0 Pro Latest | `gemini-1.0-pro-latest` |\n| Gemini 1.0 Pro Vision | `gemini-1.0-pro-vision-latest` |\n| Gemini 1.5 Pro | `gemini-1.5-pro-latest` |\n| Gemini 1.0 Pro | `gemini-pro` |\n| Gemini 1.0 Pro Vision | `gemini-pro-vision` |"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Modelos que suportam geração de conteúdo { display-mode: \"form\" }\n",
        "displayModels(modelList)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Definir modelo {display-mode: \"form\", run: \"auto\"}\n",
        "\n",
        "model_name = \"gemini-1.0-pro\" # @param ['gemini-1.0-pro','gemini-1.0-pro-001','gemini-1.0-pro-latest','gemini-1.0-pro-vision-latest','gemini-1.5-pro-latest','gemini-pro','gemini-pro-vision']"
      ],
      "metadata": {
        "id": "q_kYKUg7NC0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Implementação do modelo {display-mode: \"form\"}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name = model_name,\n",
        "    safety_settings = safety_config,\n",
        "    generation_config = generation_config\n",
        ")\n",
        "\n",
        "displayAsJSON({\n",
        "    'model_name': model_name,\n",
        "    'safety_settings': safety_config,\n",
        "    'generation_config': generation_config\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "XeJSIWYgR3mx",
        "outputId": "ee5de6c9-5616-4ee2-b979-40e07e2b6c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```JSON\n{\n    \"model_name\": \"gemini-1.0-pro\",\n    \"safety_settings\": {\n        \"HARASSMENT\": \"BLOCK_MEDIUM_AND_ABOVE\",\n        \"HATE\": \"BLOCK_MEDIUM_AND_ABOVE\",\n        \"SEXUAL\": \"BLOCK_MEDIUM_AND_ABOVE\",\n        \"DANGEROUS\": \"BLOCK_MEDIUM_AND_ABOVE\"\n    },\n    \"generation_config\": {\n        \"candidate_count\": 1,\n        \"temperature\": 0.5,\n        \"top_k\": 32,\n        \"top_p\": 0.9\n    }\n}\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilização"
      ],
      "metadata": {
        "id": "G1Fm-CkeaddT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Requisição simples {display-mode: \"form\"}\n",
        "# @markdown Ao terminar de digitar use `Ctrl+Enter` ou `Command+Enter`\n",
        "\n",
        "request_input = \"Olá, que tipo de pergunta posso fazer para você?\" # @param {type: \"string\"}\n",
        "response = model.generate_content(request_input)\n",
        "\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "tEfL_JuOagnQ",
        "outputId": "1ab1da96-7a63-4398-de6a-01ff44b5c3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Você pode me fazer perguntas sobre uma ampla gama de tópicos, incluindo:\n\n**Informações gerais:**\n* Fatos e estatísticas sobre qualquer assunto\n* Definições e explicações de conceitos\n* Notícias e eventos atuais\n* Informações sobre pessoas, lugares e coisas\n\n**Ciência e tecnologia:**\n* Princípios científicos e descobertas\n* Avanços tecnológicos e inovações\n* Questões ambientais e sustentabilidade\n* Exploração espacial e astronomia\n\n**História e cultura:**\n* Eventos históricos e figuras importantes\n* Culturas diferentes e suas tradições\n* Arte, literatura e música\n* Filosofia e religião\n\n**Geografia e viagens:**\n* Países, cidades e marcos geográficos\n* Culturas e costumes de diferentes regiões\n* Dicas de viagem e recomendações\n* Informações sobre transporte e acomodação\n\n**Saúde e bem-estar:**\n* Condições de saúde e tratamentos\n* Nutrição e fitness\n* Saúde mental e emocional\n* Cuidados pessoais e beleza\n\n**Entretenimento e esportes:**\n* Filmes, programas de TV e música\n* Esportes e atletas\n* Jogos e passatempos\n* Celebridades e cultura pop\n\n**Outros tópicos:**\n* Negócios e finanças\n* Educação e carreira\n* Política e governo\n* Idiomas e tradução\n* Matemática e lógica"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat"
      ],
      "metadata": {
        "id": "XLfFQe6_d7JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title {display-mode: \"form\"}\n",
        "\n",
        "enable_automatic_function_calling = True # @param {type: \"boolean\"}\n",
        "\n",
        "chat = model.start_chat(history = [], enable_automatic_function_calling = enable_automatic_function_calling)"
      ],
      "metadata": {
        "id": "QHlVi3aYbRSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Conversar { display-mode: \"form\" }\n",
        "# @markdown **Execute esse bloco para iniciar uma conversa** e use a palavra `fim` para **encerrar**\n",
        "\n",
        "prompt = input(\"Aguardando prompt... -> \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  chat_response = chat.send_message(prompt)\n",
        "  print(\"\\nIA: \" + chat_response.text)\n",
        "  prompt = input(\"\\nEu: \")"
      ],
      "metadata": {
        "id": "b0DICmnAflru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f3e7a18e-ba36-44f1-cd97-74a3462375f2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aguardando prompt... -> Fale o nomde cinco jogadores do corinthians\n",
            "\n",
            "IA: 1. Cássio\n",
            "2. Fagner\n",
            "3. Gil\n",
            "4. Renato Augusto\n",
            "5. Róger Guedes\n",
            "\n",
            "Eu: Qual deles é goleiro?\n",
            "\n",
            "IA: Cássio\n",
            "\n",
            "Eu: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lIgA1qUYyDYs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nzvV_5oeWdwf",
        "bx5gq4pxQGnd",
        "rj8HR6FxDs6f",
        "bDxnEVFYo3jL"
      ],
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMSwnEyGitY6U84MBtlOFiu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}